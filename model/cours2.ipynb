{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net1, self).__init__()\n",
    "        self.layer1 = nn.Linear(225*225*3, 1000)\n",
    "        self.relu   = nn.ReLU(inplace=True) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            x est le vecteur d'entrÃ©e\n",
    "        \"\"\"\n",
    "        y = self.layer1(x)\n",
    "        y = self.relu(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alex = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet (\n",
      "  (features): Sequential (\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU (inplace)\n",
      "    (2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU (inplace)\n",
      "    (5): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU (inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU (inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU (inplace)\n",
      "    (12): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential (\n",
      "    (0): Dropout (p = 0.5)\n",
      "    (1): Linear (9216 -> 4096)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Dropout (p = 0.5)\n",
      "    (4): Linear (4096 -> 4096)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): Linear (4096 -> 1000)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(alex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "im = Image.open(\"/video/CLICIDE/10A-0.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = torch.Tensor(1, 3, 225, 225)\n",
    "trans = transforms.ToTensor()\n",
    "t[0] = trans(im.resize( (225, 225) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = alex(Variable(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  9.5034\n",
       " [torch.FloatTensor of size 1x1], Variable containing:\n",
       "  669\n",
       " [torch.LongTensor of size 1x1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet (\n",
       "  (features): Sequential (\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU (inplace)\n",
       "    (2): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU (inplace)\n",
       "    (5): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU (inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU (inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU (inplace)\n",
       "    (12): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential (\n",
       "    (0): Dropout (p = 0.5)\n",
       "    (1): Linear (9216 -> 4096)\n",
       "    (2): ReLU (inplace)\n",
       "    (3): Dropout (p = 0.5)\n",
       "    (4): Linear (4096 -> 4096)\n",
       "    (5): ReLU (inplace)\n",
       "    (6): Linear (4096 -> 464)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex464 = models.AlexNet(464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.dropout.Dropout'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "<class 'torch.nn.modules.activation.ReLU'>\n",
      "<class 'torch.nn.modules.linear.Linear'>\n"
     ]
    }
   ],
   "source": [
    "for c in alex.classifier:\n",
    "    print(type(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copyParameters(net, netBase):\n",
    "    for i, f in enumerate(net.features):\n",
    "        if type(f) is torch.nn.modules.conv.Conv2d:\n",
    "            f.weight.data = netBase.features[i].weight.data\n",
    "            f.bias.data = netBase.features[i].bias.data\n",
    "    for i, c in enumerate(net.classifier):\n",
    "        if type(c) is torch.nn.modules.linear.Linear:\n",
    "            if c.weight.size() == netBase.classifier[i].weight.size():\n",
    "                c.weight.data = netBase.classifier[i].weight.data\n",
    "                c.bias.data = netBase.classifier[i].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "copyParameters(alex464, models.alexnet(pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.loss.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(alex464.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "import glob\n",
    "def readTrainingSet(folder=\".\"):\n",
    "    \"\"\"\n",
    "        Lit un dossier contenant des images\n",
    "        Retourne la liste d'image avec leur classe\n",
    "    \"\"\"\n",
    "    matchFunc = lambda x: x.split('/')[-1].split('-')[0]\n",
    "    \n",
    "    exts = ('*.jpg', '*.JPG', '*.JPEG', \"*.png\")\n",
    "    r = []\n",
    "    for ext in exts:\n",
    "        r.extend( [(im, matchFunc(im)) for im in glob.iglob(path.join(folder, ext)) if not 'wall' in im] )\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset = readTrainingSet(\"/video/CLICIDE/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "listLabel = [t[1] for t in trainset if not 'wall' in t[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464\n"
     ]
    }
   ],
   "source": [
    "s = set(listLabel)\n",
    "s = list(s)\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 6.143\n",
      "[1,    20] loss: 6.084\n",
      "[1,    30] loss: 6.041\n",
      "[1,    40] loss: 5.915\n",
      "[1,    50] loss: 5.707\n",
      "[1,    60] loss: 5.503\n",
      "[1,    70] loss: 5.481\n",
      "[1,    80] loss: 5.295\n",
      "[1,    90] loss: 5.075\n",
      "[1,   100] loss: 4.737\n",
      "[2,    10] loss: 3.990\n",
      "[2,    20] loss: 4.320\n",
      "[2,    30] loss: 4.300\n",
      "[2,    40] loss: 3.964\n",
      "[2,    50] loss: 4.021\n",
      "[2,    60] loss: 3.972\n",
      "[2,    70] loss: 4.121\n",
      "[2,    80] loss: 4.176\n",
      "[2,    90] loss: 4.125\n",
      "[2,   100] loss: 3.864\n",
      "[3,    10] loss: 2.850\n",
      "[3,    20] loss: 3.330\n",
      "[3,    30] loss: 3.021\n",
      "[3,    40] loss: 3.085\n",
      "[3,    50] loss: 3.290\n",
      "[3,    60] loss: 3.062\n",
      "[3,    70] loss: 2.940\n",
      "[3,    80] loss: 2.637\n",
      "[3,    90] loss: 2.795\n",
      "[3,   100] loss: 2.678\n",
      "[4,    10] loss: 1.977\n",
      "[4,    70] loss: 1.932\n",
      "[4,    80] loss: 2.296\n",
      "[4,    90] loss: 2.013\n",
      "[4,   100] loss: 2.111\n",
      "[5,    10] loss: 1.562\n",
      "[5,    20] loss: 1.551\n",
      "[5,    30] loss: 1.635\n",
      "[5,    40] loss: 1.625\n",
      "[5,    50] loss: 1.590\n",
      "[5,    60] loss: 1.645\n",
      "[5,    70] loss: 1.597\n",
      "[5,    80] loss: 1.866\n",
      "[5,    90] loss: 2.272\n",
      "[5,   100] loss: 2.033\n",
      "[6,    10] loss: 1.091\n",
      "[6,    20] loss: 1.133\n",
      "[6,    30] loss: 1.268\n",
      "[6,    40] loss: 0.939\n",
      "[6,    50] loss: 0.975\n",
      "[6,    60] loss: 1.105\n",
      "[6,    70] loss: 1.212\n",
      "[6,    80] loss: 1.435\n",
      "[6,    90] loss: 1.345\n",
      "[6,   100] loss: 1.096\n",
      "[7,    10] loss: 0.758\n",
      "[7,    20] loss: 0.764\n",
      "[7,    30] loss: 0.777\n",
      "[7,    40] loss: 0.684\n",
      "[7,    50] loss: 0.759\n",
      "[7,    60] loss: 0.750\n",
      "[7,    70] loss: 0.798\n",
      "[7,    80] loss: 0.874\n",
      "[7,    90] loss: 0.891\n",
      "[7,   100] loss: 0.773\n",
      "[8,    10] loss: 0.472\n",
      "[8,    20] loss: 0.424\n",
      "[8,    30] loss: 0.456\n",
      "[8,    40] loss: 0.737\n",
      "[8,    50] loss: 0.534\n",
      "[8,    60] loss: 0.558\n",
      "[8,    70] loss: 0.593\n",
      "[8,    80] loss: 0.607\n",
      "[8,    90] loss: 0.521\n",
      "[8,   100] loss: 0.552\n",
      "[9,    10] loss: 0.429\n",
      "[9,    20] loss: 0.602\n",
      "[9,    30] loss: 0.457\n",
      "[9,    40] loss: 0.694\n",
      "[9,    50] loss: 0.546\n",
      "[9,    60] loss: 0.453\n",
      "[9,    70] loss: 0.541\n",
      "[9,    80] loss: 0.514\n",
      "[9,    90] loss: 0.590\n",
      "[9,   100] loss: 0.704\n",
      "[10,    10] loss: 0.502\n",
      "[10,    20] loss: 0.533\n"
     ]
    }
   ],
   "source": [
    "batchSize = 32\n",
    "alex464\n",
    "trans = transforms.ToTensor()\n",
    "for epoch in range(10):\n",
    "    \"\"\"\n",
    "        On parcourt l'ensemble du training set\n",
    "    \"\"\"\n",
    "    alex464.train()\n",
    "    running_loss = 0.0\n",
    "    random.shuffle(trainset)    \n",
    "    for i in range(len(trainset)/batchSize):\n",
    "        \"\"\"\n",
    "         1. Charge batchSize images\n",
    "         2. Backprop\n",
    "        \"\"\"\n",
    "        inputs = torch.Tensor(batchSize, 3, 225, 225)\n",
    "        for j in range(batchSize):\n",
    "            inputs[j] = trans(Image.open(trainset[i*batchSize+j][0]).resize( (225, 225) ))\n",
    "        inputs = Variable(inputs)\n",
    "        \n",
    "        lab = Variable(torch.LongTensor([s.index(trainset[i*batchSize+j][1]) for j in range(batchSize)]))\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = alex464(inputs)\n",
    "        loss = criterion(outputs, lab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        if i % 10 == 9: # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "        Eval\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
