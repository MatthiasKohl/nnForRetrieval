{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Process the dataset :\n",
    "We have to compute the number of class, and the mean and std for image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readImages(imageFile=\"imList.txt\", openAll=True):\n",
    "    \"\"\"\n",
    "        args :\n",
    "            imageFile = file with one image path per line\n",
    "            openAll = bool : load images in memory or not\n",
    "        ret :\n",
    "            with openAll : <image path list>, <image list>\n",
    "            without openAll : <image path list>\n",
    "    \"\"\"\n",
    "    with open(imageFile) as f:\n",
    "        imList = f.read().splitlines()\n",
    "        if openAll:\n",
    "            imOpen = []\n",
    "            for im in imList:\n",
    "                i = Image.open(im).resize((225, 225), Image.BILINEAR)\n",
    "                if openAll:\n",
    "                    imOpen.append(i)\n",
    "            return imList, imOpen\n",
    "        else:\n",
    "            return imList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ComputeMean(imagesList):\n",
    "    \"\"\"\n",
    "        TODO : make efficient\n",
    "    \"\"\"\n",
    "    r,g,b = 0,0,0\n",
    "    toT = transforms.ToTensor()\n",
    "    h = len(imagesList[0])\n",
    "    w = len(imagesList[0][0])\n",
    "\n",
    "    #f = FloatProgress(min=0, max=len(imagesList))\n",
    "    #display(f)\n",
    "\n",
    "    for im in imagesList:\n",
    "        #f.value += 1\n",
    "        t = toT(im)\n",
    "        for e in t[0].view(-1):\n",
    "            r += e\n",
    "        for e in t[1].view(-1):\n",
    "            g += e\n",
    "        for e in t[2].view(-1):\n",
    "            b += e\n",
    "    return r(len(imagesList)*h*w), g/(len(imagesList)*h*w), b/(len(imagesList)*h*w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ComputeStdDev(imagesList, mean):\n",
    "    \"\"\"\n",
    "        TODO : make efficient\n",
    "    \"\"\"\n",
    "    toT = transforms.ToTensor()\n",
    "    r,g,b = 0,0,0\n",
    "    h = len(toT(imagesList[0])[0])\n",
    "    w = len(toT(imagesList[0])[0][0])\n",
    "    for im in imagesList:\n",
    "        i = toT(im)\n",
    "        for e in t[0].view(-1):\n",
    "            r += (e - mean[0])**2\n",
    "        for e in t[1].view(-1):\n",
    "            g += (e - mean[1])**2\n",
    "        for e in t[2].view(-1):\n",
    "            b += (e - mean[2])**2\n",
    "    return (r/(len(imagesList)*h*w))**0.5, (g/(len(imagesList)*h*w))**0.5, (b/(len(imagesList)*h*w))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset and compute the mean and std dev :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.42602490885018174, 0.4269285229908378, 0.418182238544934)\n",
      "(0.20014586928330125, 0.17607878531703874, 0.17040668227814146)\n"
     ]
    }
   ],
   "source": [
    "trainset, imagesList = readImages(\"CliList.txt\")\n",
    "m = ComputeMean(imagesList)\n",
    "print(m)\n",
    "s = ComputeStdDev(imagesList, m)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network as class (from nn.Module) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class maxnet(nn.Module):\n",
    "    def __init__(self, nbClass=464):\n",
    "        super(maxnet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1)),\n",
    "                nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1)),\n",
    "                nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d((3, 3), stride=(2, 2), dilation=(1, 1))\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 1000),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1000, nbClass),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 6.141\n"
     ]
    }
   ],
   "source": [
    "mymodel = maxnet()\n",
    "\n",
    "criterion = nn.loss.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mymodel.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "trainset, imagesList = readImages(\"CliList.txt\")\n",
    "testset, imagesTest = readImages(\"CliListTest.txt\")\n",
    "labels = open(\"CliConcept.txt\").read().splitlines()\n",
    "\n",
    "toT = transforms.ToTensor()\n",
    "norm = transforms.Normalize(m, s)\n",
    "\n",
    "batchSize = 32\n",
    "\n",
    "for epoch in range(2): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(len(trainset)/batchSize):\n",
    "        # get the inputs\n",
    "        elIndex = [random.randrange(0, len(trainset)) for j in range(batchSize)]\n",
    "        \n",
    "        inputs = torch.Tensor(batchSize,3,225,225)\n",
    "        for j in range(batchSize):\n",
    "            inputs[j] = norm(toT(imagesList[elIndex[j]]))\n",
    "        inputs = Variable(inputs)\n",
    "        lab = Variable(torch.LongTensor([labels.index(trainset[j].split('/')[-1].split('-')[0]) for j in elIndex]))\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = mymodel(inputs)\n",
    "        loss = criterion(outputs, lab)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 10 == 9: # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "        if i % 20 == 19: #test every 20 mini-batches\n",
    "            print('test :')\n",
    "            correct = 0\n",
    "            tot = 0\n",
    "            for j in range(len(testset)):\n",
    "                inp = torch.Tensor(1,3,225,225)\n",
    "                inp[0] = norm(toT(imagesTest[j]))\n",
    "                outputs = mymodel(Variable(inp))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = predicted.tolist()[0][0]\n",
    "                correct += (predicted == labels.index(testset[i].split('/')[-1].split('-')[0]))\n",
    "                tot += 1\n",
    "            print(\"Correct : \", correct, \"/\", tot)\n",
    "                \n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[240]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.LongTensor([240])\n",
    "t.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
