{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from __future__ import print_function\n",
    "\n",
    "from model import ModelDefinition\n",
    "from dataset import ReadImages, collection\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MeanAndStd(imageList, fname=None):\n",
    "    imageListOpen = ReadImages.openAll(trainset, (225,225))\n",
    "    m = collection.ComputeMean(imageListOpen)\n",
    "    print(\"Mean : \", m)\n",
    "    s = collection.ComputeStdDev(imageListOpen, m)\n",
    "    print(\"std dev : \", s)\n",
    "    if not fname is None:\n",
    "        with open(fname, \"w\") as f:\n",
    "            f.write('%.3f %.3f %.3f' %m)\n",
    "            f.write('\\n')\n",
    "            f.write('%.3f %.3f %.3f' %(s))\n",
    "    return m,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readMeanStd(fname='data/cli.txt'):\n",
    "    with open(fname) as f:\n",
    "        mean = map(float, f.readline().split(' '))\n",
    "        std = map(float, f.readline().split(' '))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testNet(net, testset, labels, batchSize=32):\n",
    "    \"\"\"\n",
    "        Test the network accuracy on a testset\n",
    "        Return the number of succes and the number of evaluations done\n",
    "    \"\"\"\n",
    "        net = net.eval() #set the network in eval mode\n",
    "        correct = 0\n",
    "        tot = 0\n",
    "        cpt = 0\n",
    "        for j in range(len(testset)/batchSize):\n",
    "            \n",
    "            #set the inputs\n",
    "            inp = torch.Tensor(batchSize,3,225,225).cuda()\n",
    "            for k in range(batchSize):\n",
    "                inp[k] = testTransform(testset[j*batchSize+k][0])\n",
    "                cpt += 1\n",
    "            \n",
    "            #forward pass\n",
    "            outputs = net(Variable(inp), volatile=True) #volatile the free memory after the forward\n",
    "            \n",
    "            #compute score\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = predicted.tolist()\n",
    "            for k in range(batchSize):\n",
    "                if (testset[j*batchSize+k][1] in labels):\n",
    "                    correct += (predicted[k][0] == labels.index(testset[j*batchSize+k][1]))\n",
    "                    tot += 1\n",
    "                    \n",
    "        #handle the rest of the testset\n",
    "        rest = len(testset)%batchSize\n",
    "        \n",
    "        #set inputs\n",
    "        inp = torch.Tensor(rest,3,225,225).cuda()\n",
    "        for j in range(rest):\n",
    "            inp[j] = testTransform(testset[len(testset)-rest+j][0])\n",
    "        \n",
    "        #forward\n",
    "        outputs = mymodel(Variable(inp), volatile=True)\n",
    "        \n",
    "        #compute score\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.tolist()\n",
    "        for j in range(rest):\n",
    "            if (testset[len(testset)-rest+j][1] in labels):\n",
    "               correct += (predicted[j][0] == labels.index(testset[len(testset)-rest+j][1]))\n",
    "               tot += 1\n",
    "        return correct, tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51,    10] loss: 0.129\n",
      "[51,    20] loss: 0.129\n",
      "[51,    30] loss: 0.116\n",
      "[51,    40] loss: 0.123\n",
      "[51,    50] loss: 0.220\n",
      "test :\n",
      "Correct :  79 / 165\n",
      "[52,    10] loss: 0.175\n",
      "[52,    20] loss: 0.172\n",
      "[52,    30] loss: 0.172\n",
      "[52,    40] loss: 0.128\n",
      "[52,    50] loss: 0.150\n",
      "test :\n",
      "Correct :  79 / 165\n",
      "[53,    10] loss: 0.163\n",
      "[53,    20] loss: 0.169\n",
      "[53,    30] loss: 0.139\n",
      "[53,    40] loss: 0.151\n",
      "[53,    50] loss: 0.114\n",
      "test :\n",
      "Correct :  82 / 165\n",
      "[54,    10] loss: 0.173\n",
      "[54,    20] loss: 0.194\n",
      "[54,    30] loss: 0.134\n",
      "[54,    40] loss: 0.154\n",
      "[54,    50] loss: 0.140\n",
      "test :\n",
      "Correct :  77 / 165\n",
      "[55,    10] loss: 0.150\n",
      "[55,    20] loss: 0.127\n",
      "[55,    30] loss: 0.111\n",
      "[55,    40] loss: 0.131\n",
      "[55,    50] loss: 0.119\n",
      "test :\n",
      "Correct :  86 / 165\n",
      "[56,    10] loss: 0.095\n",
      "[56,    20] loss: 0.145\n",
      "[56,    30] loss: 0.147\n",
      "[56,    40] loss: 0.156\n",
      "[56,    50] loss: 0.112\n",
      "test :\n",
      "Correct :  77 / 165\n",
      "[57,    10] loss: 0.098\n",
      "[57,    20] loss: 0.118\n",
      "[57,    30] loss: 0.089\n",
      "[57,    40] loss: 0.108\n",
      "[57,    50] loss: 0.083\n",
      "test :\n",
      "Correct :  87 / 165\n",
      "[58,    10] loss: 0.115\n",
      "[58,    20] loss: 0.121\n",
      "[58,    30] loss: 0.164\n",
      "[58,    40] loss: 0.137\n",
      "[58,    50] loss: 0.168\n",
      "test :\n",
      "Correct :  79 / 165\n",
      "[59,    10] loss: 0.126\n",
      "[59,    20] loss: 0.097\n",
      "[59,    30] loss: 0.116\n",
      "[59,    40] loss: 0.088\n",
      "[59,    50] loss: 0.120\n",
      "test :\n",
      "Correct :  80 / 165\n",
      "[60,    10] loss: 0.127\n",
      "[60,    20] loss: 0.117\n",
      "[60,    30] loss: 0.132\n",
      "[60,    40] loss: 0.139\n",
      "[60,    50] loss: 0.074\n",
      "test :\n",
      "Correct :  84 / 165\n",
      "[61,    10] loss: 0.111\n",
      "[61,    20] loss: 0.119\n",
      "[61,    30] loss: 0.112\n",
      "[61,    40] loss: 0.103\n",
      "[61,    50] loss: 0.102\n",
      "test :\n",
      "Correct :  82 / 165\n",
      "[62,    10] loss: 0.086\n",
      "[62,    20] loss: 0.114\n",
      "[62,    30] loss: 0.088\n",
      "[62,    40] loss: 0.099\n",
      "[62,    50] loss: 0.103\n",
      "test :\n",
      "Correct :  79 / 165\n",
      "[63,    10] loss: 0.080\n",
      "[63,    20] loss: 0.109\n",
      "[63,    30] loss: 0.090\n",
      "[63,    40] loss: 0.102\n",
      "[63,    50] loss: 0.062\n",
      "test :\n",
      "Correct :  85 / 165\n",
      "[64,    10] loss: 0.142\n",
      "[64,    20] loss: 0.136\n",
      "[64,    30] loss: 0.097\n",
      "[64,    40] loss: 0.097\n",
      "[64,    50] loss: 0.103\n",
      "test :\n",
      "Correct :  79 / 165\n",
      "[65,    10] loss: 0.101\n",
      "[65,    20] loss: 0.104\n",
      "[65,    30] loss: 0.087\n",
      "[65,    40] loss: 0.115\n",
      "[65,    50] loss: 0.076\n",
      "test :\n",
      "Correct :  80 / 165\n",
      "[66,    10] loss: 0.109\n",
      "[66,    20] loss: 0.085\n",
      "[66,    30] loss: 0.105\n",
      "[66,    40] loss: 0.104\n",
      "[66,    50] loss: 0.071\n",
      "test :\n",
      "Correct :  86 / 165\n",
      "[67,    10] loss: 0.064\n",
      "[67,    20] loss: 0.123\n",
      "[67,    30] loss: 0.057\n",
      "[67,    40] loss: 0.077\n",
      "[67,    50] loss: 0.096\n",
      "test :\n",
      "Correct :  85 / 165\n",
      "[68,    10] loss: 0.083\n",
      "[68,    20] loss: 0.093\n",
      "[68,    30] loss: 0.088\n",
      "[68,    40] loss: 0.089\n",
      "[68,    50] loss: 0.088\n",
      "test :\n",
      "Correct :  88 / 165\n",
      "[69,    10] loss: 0.101\n",
      "[69,    20] loss: 0.106\n",
      "[69,    30] loss: 0.116\n",
      "[69,    40] loss: 0.084\n",
      "[69,    50] loss: 0.118\n",
      "test :\n",
      "Correct :  84 / 165\n",
      "[70,    10] loss: 0.073\n",
      "[70,    20] loss: 0.103\n",
      "[70,    30] loss: 0.047\n",
      "[70,    40] loss: 0.086\n",
      "[70,    50] loss: 0.085\n",
      "test :\n",
      "Correct :  86 / 165\n",
      "[71,    10] loss: 0.094\n",
      "[71,    20] loss: 0.097\n",
      "[71,    30] loss: 0.092\n",
      "[71,    40] loss: 0.095\n",
      "[71,    50] loss: 0.095\n",
      "test :\n",
      "Correct :  89 / 165\n",
      "[72,    10] loss: 0.091\n",
      "[72,    20] loss: 0.070\n",
      "[72,    30] loss: 0.078\n",
      "[72,    40] loss: 0.066\n",
      "[72,    50] loss: 0.054\n",
      "test :\n",
      "Correct :  85 / 165\n",
      "[73,    10] loss: 0.049\n",
      "[73,    20] loss: 0.070\n",
      "[73,    30] loss: 0.068\n",
      "[73,    40] loss: 0.073\n",
      "[73,    50] loss: 0.087\n",
      "test :\n",
      "Correct :  86 / 165\n",
      "[74,    10] loss: 0.087\n",
      "[74,    20] loss: 0.098\n",
      "[74,    30] loss: 0.097\n",
      "[74,    40] loss: 0.092\n",
      "[74,    50] loss: 0.073\n",
      "test :\n",
      "Correct :  87 / 165\n",
      "[75,    10] loss: 0.082\n",
      "[75,    20] loss: 0.086\n",
      "[75,    30] loss: 0.061\n",
      "[75,    40] loss: 0.072\n",
      "[75,    50] loss: 0.081\n",
      "test :\n",
      "Correct :  82 / 165\n",
      "[76,    10] loss: 0.065\n",
      "[76,    20] loss: 0.072\n",
      "[76,    30] loss: 0.067\n",
      "[76,    40] loss: 0.102\n",
      "[76,    50] loss: 0.090\n",
      "test :\n",
      "Correct :  82 / 165\n",
      "[77,    10] loss: 0.046\n",
      "[77,    20] loss: 0.080\n",
      "[77,    30] loss: 0.074\n",
      "[77,    40] loss: 0.071\n",
      "[77,    50] loss: 0.095\n",
      "test :\n",
      "Correct :  78 / 165\n",
      "[78,    10] loss: 0.074\n",
      "[78,    20] loss: 0.084\n",
      "[78,    30] loss: 0.096\n",
      "[78,    40] loss: 0.077\n",
      "[78,    50] loss: 0.071\n",
      "test :\n",
      "Correct :  87 / 165\n",
      "[79,    10] loss: 0.069\n",
      "[79,    20] loss: 0.061\n",
      "[79,    30] loss: 0.090\n",
      "[79,    40] loss: 0.064\n",
      "[79,    50] loss: 0.054\n",
      "test :\n",
      "Correct :  85 / 165\n",
      "[80,    10] loss: 0.077\n",
      "[80,    20] loss: 0.051\n",
      "[80,    30] loss: 0.072\n",
      "[80,    40] loss: 0.068\n",
      "[80,    50] loss: 0.058\n",
      "test :\n",
      "Correct :  89 / 165\n",
      "[81,    10] loss: 0.057\n",
      "[81,    20] loss: 0.099\n",
      "[81,    30] loss: 0.068\n",
      "[81,    40] loss: 0.045\n",
      "[81,    50] loss: 0.057\n",
      "test :\n",
      "Correct :  87 / 165\n",
      "[82,    10] loss: 0.044\n",
      "[82,    20] loss: 0.057\n",
      "[82,    30] loss: 0.054\n",
      "[82,    40] loss: 0.089\n",
      "[82,    50] loss: 0.087\n",
      "test :\n",
      "Correct :  83 / 165\n",
      "[83,    10] loss: 0.067\n",
      "[83,    20] loss: 0.081\n",
      "[83,    30] loss: 0.062\n",
      "[83,    40] loss: 0.091\n",
      "[83,    50] loss: 0.074\n",
      "test :\n",
      "Correct :  83 / 165\n",
      "[84,    10] loss: 0.063\n",
      "[84,    20] loss: 0.087\n",
      "[84,    30] loss: 0.072\n",
      "[84,    40] loss: 0.054\n",
      "[84,    50] loss: 0.044\n",
      "test :\n",
      "Correct :  76 / 165\n",
      "[85,    10] loss: 0.052\n",
      "[85,    20] loss: 0.072\n",
      "[85,    30] loss: 0.076\n",
      "[85,    40] loss: 0.063\n",
      "[85,    50] loss: 0.060\n",
      "test :\n",
      "Correct :  79 / 165\n",
      "[86,    10] loss: 0.058\n",
      "[86,    20] loss: 0.073\n",
      "[86,    30] loss: 0.058\n",
      "[86,    40] loss: 0.049\n",
      "[86,    50] loss: 0.045\n",
      "test :\n",
      "Correct :  87 / 165\n",
      "[87,    10] loss: 0.045\n",
      "[87,    20] loss: 0.063\n",
      "[87,    30] loss: 0.065\n",
      "[87,    40] loss: 0.067\n",
      "[87,    50] loss: 0.067\n",
      "test :\n",
      "Correct :  80 / 165\n",
      "[88,    10] loss: 0.057\n",
      "[88,    20] loss: 0.056\n",
      "[88,    30] loss: 0.050\n",
      "[88,    40] loss: 0.043\n",
      "[88,    50] loss: 0.058\n",
      "test :\n",
      "Correct :  85 / 165\n",
      "[89,    10] loss: 0.078\n",
      "[89,    20] loss: 0.055\n",
      "[89,    30] loss: 0.057\n",
      "[89,    40] loss: 0.054\n",
      "[89,    50] loss: 0.062\n",
      "test :\n",
      "Correct :  84 / 165\n",
      "[90,    10] loss: 0.061\n",
      "[90,    20] loss: 0.070\n",
      "[90,    30] loss: 0.060\n",
      "[90,    40] loss: 0.054\n",
      "[90,    50] loss: 0.055\n",
      "test :\n",
      "Correct :  83 / 165\n",
      "[91,    10] loss: 0.079\n",
      "[91,    20] loss: 0.081\n",
      "[91,    30] loss: 0.057\n",
      "[91,    40] loss: 0.051\n",
      "[91,    50] loss: 0.054\n",
      "test :\n",
      "Correct :  85 / 165\n",
      "[92,    10] loss: 0.064\n",
      "[92,    20] loss: 0.050\n",
      "[92,    30] loss: 0.058\n",
      "[92,    40] loss: 0.071\n",
      "[92,    50] loss: 0.046\n",
      "test :\n",
      "Correct :  86 / 165\n",
      "[93,    10] loss: 0.057\n",
      "[93,    20] loss: 0.051\n",
      "[93,    30] loss: 0.052\n",
      "[93,    40] loss: 0.048\n",
      "[93,    50] loss: 0.030\n",
      "test :\n",
      "Correct :  84 / 165\n",
      "[94,    10] loss: 0.029\n",
      "[94,    20] loss: 0.049\n",
      "[94,    30] loss: 0.062\n",
      "[94,    40] loss: 0.046\n",
      "[94,    50] loss: 0.050\n",
      "test :\n",
      "Correct :  83 / 165\n",
      "[95,    10] loss: 0.049\n",
      "[95,    20] loss: 0.040\n",
      "[95,    30] loss: 0.041\n",
      "[95,    40] loss: 0.039\n",
      "[95,    50] loss: 0.046\n",
      "test :\n",
      "Correct :  85 / 165\n",
      "[96,    10] loss: 0.041\n",
      "[96,    20] loss: 0.031\n",
      "[96,    30] loss: 0.043\n",
      "[96,    40] loss: 0.046\n",
      "[96,    50] loss: 0.047\n",
      "test :\n",
      "Correct :  85 / 165\n",
      "[97,    10] loss: 0.033\n",
      "[97,    20] loss: 0.031\n",
      "[97,    30] loss: 0.060\n",
      "[97,    40] loss: 0.040\n",
      "[97,    50] loss: 0.065\n",
      "test :\n",
      "Correct :  82 / 165\n",
      "[98,    10] loss: 0.038\n",
      "[98,    20] loss: 0.054\n",
      "[98,    30] loss: 0.042\n",
      "[98,    40] loss: 0.050\n",
      "[98,    50] loss: 0.078\n",
      "test :\n",
      "Correct :  80 / 165\n",
      "[99,    10] loss: 0.048\n",
      "[99,    20] loss: 0.049\n",
      "[99,    30] loss: 0.045\n",
      "[99,    40] loss: 0.040\n",
      "[99,    50] loss: 0.049\n",
      "test :\n",
      "Correct :  90 / 165\n",
      "[100,    10] loss: 0.048\n",
      "[100,    20] loss: 0.048\n",
      "[100,    30] loss: 0.052\n",
      "[100,    40] loss: 0.051\n",
      "[100,    50] loss: 0.054\n",
      "test :\n",
      "Correct :  87 / 165\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def train(mymodel, trainset, testset, imageTransform, testTransform, criterion, optimize, saveDir=\"data/\", batchSize=32, epochStart=0, nbEpoch=50, bestScore=0):\n",
    "    \"\"\"\n",
    "        Train a network\n",
    "        inputs : \n",
    "            * trainset\n",
    "            * testset, \n",
    "            * transformations to apply to image (for train and for test)\n",
    "            * loss function (criterion)\n",
    "            * optimizer\n",
    "    \"\"\"\n",
    "    for epoch in range(ep, 100): # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        random.shuffle(trainset)    \n",
    "        for i in range(len(trainset)/batchSize):\n",
    "            # get the inputs\n",
    "            inputs = torch.Tensor(batchSize,3,225,225).cuda()\n",
    "            for j in range(batchSize):\n",
    "                inputs[j] = imageTransform(trainset[j+i*batchSize][0])\n",
    "            inputs = Variable(inputs)\n",
    "\n",
    "            #get the labels\n",
    "            lab = Variable(torch.LongTensor([labels.index(trainset[j+i*batchSize][1]) for j in range(batchSize)]).cuda())\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = mymodel(inputs)\n",
    "            loss = criterion(outputs, lab)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 10 == 9: # print every 10 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss / 10))\n",
    "                running_loss = 0.0\n",
    "\n",
    "            if i % 50 == 49: #test every 20 mini-batches\n",
    "                print('test :')\n",
    "                c, t = testNet(mymodel, testset, labels, batchSize=batchSize)\n",
    "                print(\"Correct : \", c, \"/\", t)\n",
    "                if (correct >= bestScore):\n",
    "                    best = mymodel\n",
    "                    bestScore = correct\n",
    "                    torch.save(best, \"bestModel.ckpt\")\n",
    "                #else:\n",
    "                #    mymodel = best\n",
    "                torch.save(mymodel, path.join(saveDir,\"model-\"+str(epoch)+\".ckpt\"))\n",
    "                mymodel.train() #set the model in train mode\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "    #training and test sets\n",
    "    trainset = ReadImages.readImageswithPattern('/video/CLICIDE', lambda x:x.split('/')[-1].split('-')[0])\n",
    "    testset = ReadImages.readImageswithPattern('/video/CLICIDE/test/', lambda x:x.split('/')[-1].split('-')[0])\n",
    "\n",
    "    m, s = readMeanStd('data/cli.txt')\n",
    "    \n",
    "    #define the labels list\n",
    "    listLabel = [t[1] for t in trainset if not 'wall' in t[1]]\n",
    "    labels = list(set(listLabel)) #we have to give a number for each label\n",
    "    \n",
    "    #open the images\n",
    "    #do that only if it fits in memory !\n",
    "    for i in range(len(trainset)):\n",
    "        trainset[i] = (Image.open(trainset[i][0]), trainset[i][1])\n",
    "        \n",
    "    for i in range(len(testset)):\n",
    "        testset[i] = (Image.open(testset[i][0]), testset[i][1])\n",
    "        \n",
    "    \n",
    "    #define the model\n",
    "    #mymodel = ModelDefinition.Maxnet()\n",
    "    #ModelDefinition.copyParameters(mymodel, models.alexnet(pretrained=True))\n",
    "    \n",
    "    #or load the model\n",
    "    mymodel = torch.load('bestModel.ckpt')\n",
    "    \n",
    "    criterion = nn.loss.CrossEntropyLoss()\n",
    "    mymodel.train().cuda()\n",
    "    \n",
    "    #define the optimizer to only the classifier with lr of 1e-2\n",
    "    optimizer=optim.SGD([\n",
    "                    {'params': mymodel.classifier.parameters()},\n",
    "                    {'params': mymodel.features.parameters(), 'lr': 0.0}\n",
    "                ], lr=1e-2, momentum=0.9)\n",
    "\n",
    "\n",
    "    imageTransform = transforms.Compose( (transforms.Scale(300), transforms.RandomCrop(225), transforms.ToTensor(), transforms.Normalize(m,s)) )\n",
    "    testTransform = transforms.Compose( (transforms.Scale(225), transforms.CenterCrop(225), transforms.ToTensor(), transforms.Normalize(m,s)))\n",
    "    batchSize = 64\n",
    "    \n",
    "    \n",
    "    #define the optimizer train on all the network\n",
    "    optimizer=optim.SGD(mymodel.parameters(), lr=0.0001, momentum=0.9)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
